{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Inference Demo\n",
    "\n",
    "This notebook demonstrates how to use a trained Transformer model for English-to-Russian translation by **loading pre-trained weights** from a file.\n",
    "\n",
    "We will:\n",
    "1.  Load all the necessary functions from our `transformer.py` script.\n",
    "2.  Load the vocabulary that maps words to tokens.\n",
    "3.  Load the trained model parameters from the `transformer_weights.msgpack` file.\n",
    "4.  Define an `translate` function that performs autoregressive inference.\n",
    "5.  Try out the model on new sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax.serialization import from_bytes\n",
    "\n",
    "# Import all the building blocks from our script\n",
    "from transformer import (\n",
    "    text_to_token_ids,\n",
    "    token_embeddings,\n",
    "    positional_embeddings,\n",
    "    transformer_encoder,\n",
    "    forward,\n",
    "    init_params\n",
    ")\n",
    "\n",
    "# We also need the data loading functions\n",
    "from data import load_dataset_and_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading vocabulary...\")\n",
    "vocab, _, _, vocab_size = load_dataset_and_vocab(split=\"train\", max_vocab_size=20000)\n",
    "id_to_token = {v: k for k, v in vocab.items()} # For decoding the output\n",
    "print(f\"Vocabulary loaded. Size: {vocab_size} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Trained Model Weights\n",
    "\n",
    "Here, we load the `params` object that was saved by our training script. Note that we first need to initialize a model with the same architecture to act as a template, and then we load the saved weights into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to match the saved model\n",
    "D_MODEL = 128\n",
    "D_FF = D_MODEL * 4\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 8\n",
    "\n",
    "# 1. Initialize a model with the correct structure but random weights\n",
    "key = jax.random.PRNGKey(42)\n",
    "template_params = init_params(key, vocab_size=vocab_size, d_model=D_MODEL, d_ff=D_FF, n_heads=N_HEADS, n_layers=N_LAYERS)\n",
    "\n",
    "# 2. Load the saved byte data from the file\n",
    "print(\"Loading saved model weights from transformer_weights.msgpack...\")\n",
    "with open(\"transformer_weights.msgpack\", \"rb\") as f:\n",
    "    byte_data = f.read()\n",
    "\n",
    "# 3. Restore the trained parameters into our template model\n",
    "loaded_params = from_bytes(template_params, byte_data)\n",
    "\n",
    "print(\"âœ… Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(english_sentence: str, params: dict, vocab: dict, max_output_len: int = 32, d_model: int = 128):\n",
    "    \"\"\"\n",
    "    Translates an English sentence to Russian using the trained Transformer model.\n",
    "    \"\"\"\n",
    "    # Get special token IDs\n",
    "    sos_id = vocab['<SOS>']\n",
    "    eos_id = vocab['<EOS>']\n",
    "    \n",
    "    # 1. Tokenize the input English sentence\n",
    "    enc_input = text_to_token_ids([english_sentence], vocab, max_len=32)\n",
    "    \n",
    "    # 2. Run the encoder pass (this is done only once)\n",
    "    inf_key = jax.random.PRNGKey(0)\n",
    "    keys = jax.random.split(inf_key, 12)\n",
    "    enc_keys = keys[:6]\n",
    "    enc_emb = token_embeddings(enc_input, params['embedding']['W_emb'], d_model)\n",
    "    enc_emb += positional_embeddings(max_len=32, d_model=d_model)\n",
    "    enc_output = transformer_encoder(enc_emb, params['encoder'], enc_keys, d_model=d_model, training=False)\n",
    "\n",
    "    # 3. Autoregressive decoding loop\n",
    "    dec_input_ids = [sos_id]\n",
    "    \n",
    "    for _ in range(max_output_len):\n",
    "        current_len = len(dec_input_ids)\n",
    "        dec_input = jnp.array([dec_input_ids + [0] * (32 - current_len)])\n",
    "        \n",
    "        logits, _ = forward(params, enc_input, dec_input, vocab_size=len(vocab), d_model=d_model, training=False, key=inf_key)\n",
    "        \n",
    "        last_token_logits = logits[0, current_len - 1, :]\n",
    "        predicted_token_id = jnp.argmax(last_token_logits).item()\n",
    "        \n",
    "        dec_input_ids.append(predicted_token_id)\n",
    "        \n",
    "        if predicted_token_id == eos_id:\n",
    "            break\n",
    "            \n",
    "    # 4. Convert token IDs back to words\n",
    "    output_words = []\n",
    "    for token_id in dec_input_ids[1:]:\n",
    "        if token_id == eos_id:\n",
    "            break\n",
    "        output_words.append(id_to_token.get(token_id, '<UNK>'))\n",
    "        \n",
    "    return \" \".join(output_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try it Out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"I love to code.\",\n",
    "    \"What is your name?\",\n",
    "    \"This is a small transformer.\",\n",
    "    \"Let's go to the park.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translation = translate(sentence, loaded_params, vocab, d_model=D_MODEL)\n",
    "    print(f\"Input:  {sentence}\")\n",
    "    print(f\"Output: {translation}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}